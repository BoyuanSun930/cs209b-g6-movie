{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import string\n",
    "import ast\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "imdb_movie = pd.read_csv('data/imdb_multilabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>topRank</th>\n",
       "      <th>bottomRank</th>\n",
       "      <th>metaScore</th>\n",
       "      <th>plot</th>\n",
       "      <th>rating</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>runningTimeInMinutes</th>\n",
       "      <th>userRatingCount</th>\n",
       "      <th>userScore</th>\n",
       "      <th>year</th>\n",
       "      <th>all_genre</th>\n",
       "      <th>genre</th>\n",
       "      <th>plot_list</th>\n",
       "      <th>genreCount</th>\n",
       "      <th>genre_code</th>\n",
       "      <th>all_genre_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I, Tonya</td>\n",
       "      <td>tt5580036</td>\n",
       "      <td>930.0</td>\n",
       "      <td>17643.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>From the proverbial wrong side of the tracks i...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>67667.0</td>\n",
       "      <td>46</td>\n",
       "      <td>120.0</td>\n",
       "      <td>235</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Biography', 'Comedy', 'Drama', 'Sport']</td>\n",
       "      <td>sport</td>\n",
       "      <td>['From', 'the', 'proverbial', 'wrong', 'side',...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cars 3</td>\n",
       "      <td>tt3606752</td>\n",
       "      <td>2256.0</td>\n",
       "      <td>11547.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Blindsided by a new generation of blazing-fast...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>41896.0</td>\n",
       "      <td>41</td>\n",
       "      <td>102.0</td>\n",
       "      <td>232</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Animation', 'Adventure', 'Comedy', 'Family',...</td>\n",
       "      <td>sport</td>\n",
       "      <td>['Blindsided', 'by', 'a', 'new', 'generation',...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Creed</td>\n",
       "      <td>tt3076658</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17840.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Adonis Johnson is the son of the famous boxing...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>193206.0</td>\n",
       "      <td>42</td>\n",
       "      <td>133.0</td>\n",
       "      <td>614</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>['Drama', 'Sport']</td>\n",
       "      <td>sport</td>\n",
       "      <td>['Adonis', 'Johnson', 'is', 'the', 'son', 'of'...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Battle of the Sexes</td>\n",
       "      <td>tt4622512</td>\n",
       "      <td>2303.0</td>\n",
       "      <td>11228.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>In the wake of the sexual revolution and the r...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>27960.0</td>\n",
       "      <td>46</td>\n",
       "      <td>121.0</td>\n",
       "      <td>102</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Biography', 'Comedy', 'Drama', 'Sport']</td>\n",
       "      <td>sport</td>\n",
       "      <td>['In', 'the', 'wake', 'of', 'the', 'sexual', '...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Borg McEnroe</td>\n",
       "      <td>tt5727282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12891.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>The story of the 1980s tennis rivalry between ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>13</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Biography', 'Drama', 'Sport']</td>\n",
       "      <td>sport</td>\n",
       "      <td>['The', 'story', 'of', 'the', '1980s', 'tennis...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                title    imdb_id  topRank  bottomRank  metaScore  \\\n",
       "0           0             I, Tonya  tt5580036    930.0     17643.0       77.0   \n",
       "1           1               Cars 3  tt3606752   2256.0     11547.0       59.0   \n",
       "2           2                Creed  tt3076658    847.0     17840.0       82.0   \n",
       "3           3  Battle of the Sexes  tt4622512   2303.0     11228.0       73.0   \n",
       "4           4         Borg McEnroe  tt5727282      NaN     12891.0       57.0   \n",
       "\n",
       "                                                plot  rating  ratingCount  \\\n",
       "0  From the proverbial wrong side of the tracks i...     7.6      67667.0   \n",
       "1  Blindsided by a new generation of blazing-fast...     6.8      41896.0   \n",
       "2  Adonis Johnson is the son of the famous boxing...     7.6     193206.0   \n",
       "3  In the wake of the sexual revolution and the r...     6.8      27960.0   \n",
       "4  The story of the 1980s tennis rivalry between ...     7.0       9800.0   \n",
       "\n",
       "   reviewCount  runningTimeInMinutes  userRatingCount  userScore    year  \\\n",
       "0           46                 120.0              235        7.8  2017.0   \n",
       "1           41                 102.0              232        6.9  2017.0   \n",
       "2           42                 133.0              614        8.0  2015.0   \n",
       "3           46                 121.0              102        6.3  2017.0   \n",
       "4           13                 107.0                0        NaN  2017.0   \n",
       "\n",
       "                                           all_genre  genre  \\\n",
       "0          ['Biography', 'Comedy', 'Drama', 'Sport']  sport   \n",
       "1  ['Animation', 'Adventure', 'Comedy', 'Family',...  sport   \n",
       "2                                 ['Drama', 'Sport']  sport   \n",
       "3          ['Biography', 'Comedy', 'Drama', 'Sport']  sport   \n",
       "4                    ['Biography', 'Drama', 'Sport']  sport   \n",
       "\n",
       "                                           plot_list  genreCount  genre_code  \\\n",
       "0  ['From', 'the', 'proverbial', 'wrong', 'side',...           4           0   \n",
       "1  ['Blindsided', 'by', 'a', 'new', 'generation',...           5           0   \n",
       "2  ['Adonis', 'Johnson', 'is', 'the', 'son', 'of'...           2           0   \n",
       "3  ['In', 'the', 'wake', 'of', 'the', 'sexual', '...           4           0   \n",
       "4  ['The', 'story', 'of', 'the', '1980s', 'tennis...           3           0   \n",
       "\n",
       "                                    all_genre_encode  \n",
       "0  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...  \n",
       "1  [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. ...  \n",
       "2  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...  \n",
       "3  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...  \n",
       "4  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_movie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single-label encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = dict(zip(imdb_movie.genre.unique(), range(20)))\n",
    "\n",
    "imdb_movie['genre_code'] = imdb_movie.genre.replace(genre_dict).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>topRank</th>\n",
       "      <th>bottomRank</th>\n",
       "      <th>metaScore</th>\n",
       "      <th>plot</th>\n",
       "      <th>rating</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>runningTimeInMinutes</th>\n",
       "      <th>userRatingCount</th>\n",
       "      <th>userScore</th>\n",
       "      <th>year</th>\n",
       "      <th>all_genre</th>\n",
       "      <th>genre</th>\n",
       "      <th>plot_list</th>\n",
       "      <th>genreCount</th>\n",
       "      <th>genre_code</th>\n",
       "      <th>all_genre_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I, Tonya</td>\n",
       "      <td>tt5580036</td>\n",
       "      <td>930.0</td>\n",
       "      <td>17643.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>From the proverbial wrong side of the tracks i...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>67667.0</td>\n",
       "      <td>46</td>\n",
       "      <td>120.0</td>\n",
       "      <td>235</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Biography', 'Comedy', 'Drama', 'Sport']</td>\n",
       "      <td>sport</td>\n",
       "      <td>['From', 'the', 'proverbial', 'wrong', 'side',...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cars 3</td>\n",
       "      <td>tt3606752</td>\n",
       "      <td>2256.0</td>\n",
       "      <td>11547.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Blindsided by a new generation of blazing-fast...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>41896.0</td>\n",
       "      <td>41</td>\n",
       "      <td>102.0</td>\n",
       "      <td>232</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Animation', 'Adventure', 'Comedy', 'Family',...</td>\n",
       "      <td>sport</td>\n",
       "      <td>['Blindsided', 'by', 'a', 'new', 'generation',...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Creed</td>\n",
       "      <td>tt3076658</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17840.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Adonis Johnson is the son of the famous boxing...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>193206.0</td>\n",
       "      <td>42</td>\n",
       "      <td>133.0</td>\n",
       "      <td>614</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>['Drama', 'Sport']</td>\n",
       "      <td>sport</td>\n",
       "      <td>['Adonis', 'Johnson', 'is', 'the', 'son', 'of'...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Battle of the Sexes</td>\n",
       "      <td>tt4622512</td>\n",
       "      <td>2303.0</td>\n",
       "      <td>11228.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>In the wake of the sexual revolution and the r...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>27960.0</td>\n",
       "      <td>46</td>\n",
       "      <td>121.0</td>\n",
       "      <td>102</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Biography', 'Comedy', 'Drama', 'Sport']</td>\n",
       "      <td>sport</td>\n",
       "      <td>['In', 'the', 'wake', 'of', 'the', 'sexual', '...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Borg McEnroe</td>\n",
       "      <td>tt5727282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12891.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>The story of the 1980s tennis rivalry between ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>13</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Biography', 'Drama', 'Sport']</td>\n",
       "      <td>sport</td>\n",
       "      <td>['The', 'story', 'of', 'the', '1980s', 'tennis...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                title    imdb_id  topRank  bottomRank  metaScore  \\\n",
       "0           0             I, Tonya  tt5580036    930.0     17643.0       77.0   \n",
       "1           1               Cars 3  tt3606752   2256.0     11547.0       59.0   \n",
       "2           2                Creed  tt3076658    847.0     17840.0       82.0   \n",
       "3           3  Battle of the Sexes  tt4622512   2303.0     11228.0       73.0   \n",
       "4           4         Borg McEnroe  tt5727282      NaN     12891.0       57.0   \n",
       "\n",
       "                                                plot  rating  ratingCount  \\\n",
       "0  From the proverbial wrong side of the tracks i...     7.6      67667.0   \n",
       "1  Blindsided by a new generation of blazing-fast...     6.8      41896.0   \n",
       "2  Adonis Johnson is the son of the famous boxing...     7.6     193206.0   \n",
       "3  In the wake of the sexual revolution and the r...     6.8      27960.0   \n",
       "4  The story of the 1980s tennis rivalry between ...     7.0       9800.0   \n",
       "\n",
       "   reviewCount  runningTimeInMinutes  userRatingCount  userScore    year  \\\n",
       "0           46                 120.0              235        7.8  2017.0   \n",
       "1           41                 102.0              232        6.9  2017.0   \n",
       "2           42                 133.0              614        8.0  2015.0   \n",
       "3           46                 121.0              102        6.3  2017.0   \n",
       "4           13                 107.0                0        NaN  2017.0   \n",
       "\n",
       "                                           all_genre  genre  \\\n",
       "0          ['Biography', 'Comedy', 'Drama', 'Sport']  sport   \n",
       "1  ['Animation', 'Adventure', 'Comedy', 'Family',...  sport   \n",
       "2                                 ['Drama', 'Sport']  sport   \n",
       "3          ['Biography', 'Comedy', 'Drama', 'Sport']  sport   \n",
       "4                    ['Biography', 'Drama', 'Sport']  sport   \n",
       "\n",
       "                                           plot_list  genreCount  genre_code  \\\n",
       "0  ['From', 'the', 'proverbial', 'wrong', 'side',...           4           0   \n",
       "1  ['Blindsided', 'by', 'a', 'new', 'generation',...           5           0   \n",
       "2  ['Adonis', 'Johnson', 'is', 'the', 'son', 'of'...           2           0   \n",
       "3  ['In', 'the', 'wake', 'of', 'the', 'sexual', '...           4           0   \n",
       "4  ['The', 'story', 'of', 'the', '1980s', 'tennis...           3           0   \n",
       "\n",
       "                                    all_genre_encode  \n",
       "0  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...  \n",
       "1  [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. ...  \n",
       "2  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...  \n",
       "3  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...  \n",
       "4  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict['sci-fi'] = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi-label encode as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_encoder(all_genre_list):\n",
    "    \"\"\" This function takes a list of genre with a dictionary that keeps track of the index of the genre\n",
    "    INPUTS\n",
    "    ------\n",
    "    all_genre_list: list of genres\n",
    "    genre_dict: dictionary of indexs\n",
    "    \n",
    "    OUTPUTS\n",
    "    -------\n",
    "    np array in {0, 1}\n",
    "    \"\"\"\n",
    "    encode = np.zeros(20)\n",
    "    all_genre_list = ast.literal_eval(all_genre_list)\n",
    "    for genre in all_genre_list:\n",
    "        if genre.lower() in genre_dict:\n",
    "            encode[genre_dict[genre.lower()]] = 1\n",
    "    return list(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imdb_movie['all_genre_encode'] = imdb_movie['all_genre'].apply(multi_label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_movie['all_genre_encode'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_movie['plot_list'] = imdb_movie['plot_list'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From',\n",
       " 'the',\n",
       " 'proverbial',\n",
       " 'wrong',\n",
       " 'side',\n",
       " 'of',\n",
       " 'the',\n",
       " 'tracks',\n",
       " 'in',\n",
       " 'Portland,',\n",
       " 'Oregon,',\n",
       " 'former',\n",
       " 'competitive',\n",
       " 'figure',\n",
       " 'skater',\n",
       " 'Tonya',\n",
       " 'Harding',\n",
       " 'was',\n",
       " 'never',\n",
       " 'fully',\n",
       " 'accepted',\n",
       " 'in',\n",
       " 'the',\n",
       " 'figure',\n",
       " 'skating',\n",
       " 'community',\n",
       " 'for',\n",
       " 'not',\n",
       " 'inherently',\n",
       " 'being',\n",
       " 'the',\n",
       " 'image',\n",
       " 'of',\n",
       " 'grace,',\n",
       " 'breeding',\n",
       " 'and',\n",
       " 'privilege',\n",
       " 'that',\n",
       " 'the',\n",
       " 'community',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'portray,',\n",
       " 'despite',\n",
       " 'she',\n",
       " 'being',\n",
       " 'naturally',\n",
       " 'gifted',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sport',\n",
       " 'athletically.',\n",
       " 'Despite',\n",
       " 'ultimately',\n",
       " 'garnering',\n",
       " 'some',\n",
       " 'success',\n",
       " 'in',\n",
       " 'figure',\n",
       " 'skating',\n",
       " 'being',\n",
       " 'national',\n",
       " 'champion,',\n",
       " 'a',\n",
       " 'world',\n",
       " 'championship',\n",
       " 'medalist,',\n",
       " 'an',\n",
       " 'Olympian,',\n",
       " 'and',\n",
       " 'being',\n",
       " 'the',\n",
       " 'first',\n",
       " 'American',\n",
       " 'woman',\n",
       " 'to',\n",
       " 'complete',\n",
       " 'a',\n",
       " 'Triple',\n",
       " 'Axel',\n",
       " 'in',\n",
       " 'competition,',\n",
       " 'she',\n",
       " 'is',\n",
       " 'arguably',\n",
       " 'best',\n",
       " 'known',\n",
       " 'for',\n",
       " 'her',\n",
       " 'association',\n",
       " 'to',\n",
       " '\"the',\n",
       " 'incident\":',\n",
       " 'the',\n",
       " 'leg',\n",
       " 'bashing',\n",
       " 'on',\n",
       " 'January',\n",
       " '6,',\n",
       " '1994',\n",
       " 'of',\n",
       " 'her',\n",
       " 'competitor,',\n",
       " 'Nancy',\n",
       " 'Kerrigan,',\n",
       " 'who,',\n",
       " 'unlike',\n",
       " 'Tonya,',\n",
       " 'was',\n",
       " 'everything',\n",
       " 'that',\n",
       " 'the',\n",
       " 'figure',\n",
       " 'skating',\n",
       " 'community',\n",
       " 'wanted',\n",
       " 'in',\n",
       " 'their',\n",
       " 'representatives.',\n",
       " 'Her',\n",
       " 'association',\n",
       " 'to',\n",
       " 'that',\n",
       " 'incident',\n",
       " 'led',\n",
       " 'to',\n",
       " 'Tonya',\n",
       " 'being',\n",
       " 'banned',\n",
       " 'from',\n",
       " 'competitive',\n",
       " 'figure',\n",
       " 'skating',\n",
       " 'for',\n",
       " 'life.',\n",
       " \"Tonya's\",\n",
       " 'story',\n",
       " 'from',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'of',\n",
       " 'her',\n",
       " 'figure',\n",
       " 'skating',\n",
       " 'life',\n",
       " 'at',\n",
       " 'age',\n",
       " 'four',\n",
       " 'to',\n",
       " 'the',\n",
       " 'aftermath',\n",
       " 'of',\n",
       " 'the',\n",
       " 'incident',\n",
       " 'is',\n",
       " 'presented.',\n",
       " 'Besides',\n",
       " 'Tonya',\n",
       " 'herself,',\n",
       " 'key',\n",
       " 'people',\n",
       " 'in',\n",
       " 'her',\n",
       " 'life',\n",
       " 'give',\n",
       " 'their',\n",
       " 'perspective',\n",
       " 'of',\n",
       " 'their',\n",
       " 'role',\n",
       " 'in',\n",
       " 'her',\n",
       " 'life.',\n",
       " 'Although',\n",
       " 'they',\n",
       " 'may',\n",
       " 'agree',\n",
       " 'on',\n",
       " 'the',\n",
       " 'broad',\n",
       " 'issues',\n",
       " 'at',\n",
       " 'hand,',\n",
       " 'such',\n",
       " 'as',\n",
       " 'that',\n",
       " 'the',\n",
       " 'incident',\n",
       " 'did',\n",
       " 'occur,',\n",
       " 'they',\n",
       " 'may',\n",
       " 'vary',\n",
       " 'widely',\n",
       " 'in',\n",
       " 'their',\n",
       " 'recollection',\n",
       " 'of',\n",
       " 'the',\n",
       " 'details.',\n",
       " 'These',\n",
       " 'people',\n",
       " 'are:',\n",
       " 'her',\n",
       " 'waitress',\n",
       " 'mother',\n",
       " 'Lavona',\n",
       " 'Golden,',\n",
       " 'who',\n",
       " 'despite',\n",
       " 'having',\n",
       " 'paid',\n",
       " 'for',\n",
       " 'her',\n",
       " 'expensive',\n",
       " 'figure',\n",
       " 'skating',\n",
       " 'lessons,',\n",
       " 'was',\n",
       " 'abusive',\n",
       " 'toward',\n",
       " 'her',\n",
       " 'physically',\n",
       " 'and',\n",
       " 'emotionally,',\n",
       " 'never',\n",
       " 'believing',\n",
       " 'she',\n",
       " 'being',\n",
       " 'good',\n",
       " 'enough',\n",
       " 'in',\n",
       " 'any',\n",
       " 'aspect',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word,',\n",
       " 'and',\n",
       " 'who',\n",
       " 'pulled',\n",
       " 'her',\n",
       " 'from',\n",
       " 'school',\n",
       " 'to',\n",
       " 'focus',\n",
       " 'solely',\n",
       " 'on',\n",
       " 'the',\n",
       " 'figure',\n",
       " 'skating;',\n",
       " 'Diane',\n",
       " 'Rawlinson,',\n",
       " 'her',\n",
       " 'first',\n",
       " 'and',\n",
       " 'longest',\n",
       " 'serving',\n",
       " 'coach,',\n",
       " 'who,',\n",
       " 'for',\n",
       " 'good',\n",
       " 'or',\n",
       " 'bad,',\n",
       " 'largely',\n",
       " 'let',\n",
       " 'Tonya',\n",
       " 'be',\n",
       " 'Tonya',\n",
       " 'in',\n",
       " 'the',\n",
       " 'way',\n",
       " 'she',\n",
       " 'presented',\n",
       " 'herself',\n",
       " 'to',\n",
       " 'the',\n",
       " 'figure',\n",
       " 'skating',\n",
       " 'world;',\n",
       " 'Jeff',\n",
       " 'Gillooly,',\n",
       " 'her',\n",
       " 'first',\n",
       " 'husband,',\n",
       " 'the',\n",
       " 'two',\n",
       " 'who',\n",
       " 'also',\n",
       " 'had',\n",
       " 'a',\n",
       " 'turbulent',\n",
       " 'relationship',\n",
       " 'on',\n",
       " 'a',\n",
       " 'need',\n",
       " 'to',\n",
       " 'be',\n",
       " 'loved',\n",
       " 'perhaps',\n",
       " 'without',\n",
       " 'truly',\n",
       " 'loving',\n",
       " 'the',\n",
       " 'other;',\n",
       " \"Jeff's\",\n",
       " 'friend',\n",
       " 'and',\n",
       " \"Tonya's\",\n",
       " 'bodyguard',\n",
       " 'Shawn',\n",
       " 'Eckardt,',\n",
       " 'a',\n",
       " 'dim',\n",
       " 'bulb',\n",
       " 'who',\n",
       " 'believed',\n",
       " 'himself',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'bigger',\n",
       " 'player',\n",
       " 'in',\n",
       " 'the',\n",
       " 'big',\n",
       " 'scheme',\n",
       " 'of',\n",
       " 'life',\n",
       " 'than',\n",
       " 'he',\n",
       " 'actually',\n",
       " 'was;',\n",
       " 'and',\n",
       " 'sports',\n",
       " 'journalist',\n",
       " 'Martin',\n",
       " 'Maddox,',\n",
       " 'a',\n",
       " 'fictional',\n",
       " 'character',\n",
       " 'who',\n",
       " 'provides',\n",
       " 'general',\n",
       " 'commentary',\n",
       " 'of',\n",
       " 'what',\n",
       " 'the',\n",
       " 'sports',\n",
       " 'media',\n",
       " 'as',\n",
       " 'a',\n",
       " 'collective',\n",
       " 'wanted',\n",
       " 'out',\n",
       " 'of',\n",
       " 'Tonya',\n",
       " 'and',\n",
       " 'the',\n",
       " 'incident.',\n",
       " 'Loved',\n",
       " 'for',\n",
       " 'a',\n",
       " 'fleeting',\n",
       " 'moment',\n",
       " 'and',\n",
       " 'then',\n",
       " 'hated',\n",
       " 'for',\n",
       " 'life,',\n",
       " 'Tonya',\n",
       " 'Harding,',\n",
       " 'the',\n",
       " 'child',\n",
       " 'prodigy',\n",
       " 'who',\n",
       " 'was',\n",
       " 'forced',\n",
       " 'into',\n",
       " 'the',\n",
       " 'realm',\n",
       " 'of',\n",
       " 'skating',\n",
       " 'by',\n",
       " 'her',\n",
       " 'overbearing',\n",
       " 'and',\n",
       " 'abusive',\n",
       " 'mother,',\n",
       " 'LaVona',\n",
       " 'Golden,',\n",
       " 'recounts',\n",
       " 'the',\n",
       " 'events',\n",
       " 'in',\n",
       " 'her',\n",
       " 'bumpy',\n",
       " 'life.',\n",
       " 'From',\n",
       " 'her',\n",
       " 'harmful',\n",
       " 'relationship',\n",
       " 'with',\n",
       " 'her',\n",
       " 'first',\n",
       " 'beau,',\n",
       " 'Jeff',\n",
       " 'Gillooly,',\n",
       " 'to',\n",
       " 'her',\n",
       " 'utter',\n",
       " 'defeat',\n",
       " 'in',\n",
       " 'the',\n",
       " '1992',\n",
       " 'Winter',\n",
       " 'Olympics,',\n",
       " 'and',\n",
       " 'from',\n",
       " 'that',\n",
       " 'disgraceful',\n",
       " 'incident',\n",
       " 'with',\n",
       " 'her',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'fellow',\n",
       " 'skater,',\n",
       " 'Nancy',\n",
       " 'Kerrigan,',\n",
       " 'to',\n",
       " 'her',\n",
       " 'last',\n",
       " 'chance',\n",
       " 'at',\n",
       " 'the',\n",
       " '1994',\n",
       " 'Winter',\n",
       " 'Olympics,',\n",
       " 'Tonya',\n",
       " 'was',\n",
       " 'always',\n",
       " 'a',\n",
       " 'victim',\n",
       " 'of',\n",
       " 'her',\n",
       " 'abundant',\n",
       " 'talent.',\n",
       " 'However,',\n",
       " 'talent',\n",
       " 'alone',\n",
       " \"isn't\",\n",
       " 'enough,',\n",
       " 'even',\n",
       " 'if',\n",
       " 'you',\n",
       " 'are',\n",
       " 'the',\n",
       " 'first',\n",
       " 'American',\n",
       " 'figure',\n",
       " 'skater',\n",
       " 'who',\n",
       " 'can',\n",
       " 'perform',\n",
       " 'to',\n",
       " 'perfection',\n",
       " 'the',\n",
       " 'notoriously',\n",
       " 'difficult',\n",
       " 'triple',\n",
       " 'axel',\n",
       " 'in',\n",
       " 'competition.',\n",
       " 'In',\n",
       " '1991,',\n",
       " 'talented',\n",
       " 'figure',\n",
       " 'skater',\n",
       " 'Tonya',\n",
       " 'Harding',\n",
       " 'becomes',\n",
       " 'the',\n",
       " 'first',\n",
       " 'American',\n",
       " 'woman',\n",
       " 'to',\n",
       " 'complete',\n",
       " 'a',\n",
       " 'triple',\n",
       " 'axel',\n",
       " 'during',\n",
       " 'a',\n",
       " 'competition.',\n",
       " 'In',\n",
       " '1994,',\n",
       " 'her',\n",
       " 'world',\n",
       " 'comes',\n",
       " 'crashing',\n",
       " 'down',\n",
       " 'when',\n",
       " 'her',\n",
       " 'ex-husband',\n",
       " 'conspires',\n",
       " 'to',\n",
       " 'injure',\n",
       " 'Nancy',\n",
       " 'Kerrigan,',\n",
       " 'a',\n",
       " 'fellow',\n",
       " 'Olympic',\n",
       " 'hopeful,',\n",
       " 'in',\n",
       " 'a',\n",
       " 'poorly',\n",
       " 'conceived',\n",
       " 'attack',\n",
       " 'that',\n",
       " 'forces',\n",
       " 'the',\n",
       " 'young',\n",
       " 'woman',\n",
       " 'to',\n",
       " 'withdraw',\n",
       " 'from',\n",
       " 'the',\n",
       " 'national',\n",
       " 'championship.',\n",
       " \"Harding's\",\n",
       " 'life',\n",
       " 'and',\n",
       " 'legacy',\n",
       " 'instantly',\n",
       " 'become',\n",
       " 'tarnished',\n",
       " 'as',\n",
       " \"she's\",\n",
       " 'forever',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'infamous',\n",
       " 'scandals',\n",
       " 'in',\n",
       " 'sports',\n",
       " 'history.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_movie['plot_list'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imdb_movie['plot'], \n",
    "                                                                            imdb_movie['all_genre_encode'],\n",
    "                                                                            test_size = 0.2,\n",
    "                                                                            random_state = 209,\n",
    "                                                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_true, y_score, method='avg'):\n",
    "    if method == 'avg':\n",
    "        return np.mean(np.mean(y_true == y_score, axis=1))\n",
    "    elif method == 'exact':\n",
    "        return metrics.accuracy_score(y_true, y_score)\n",
    "    elif method == 'recall':\n",
    "        return np.mean([metrics.recall_score(y_true[:,i], y_score[:,i]) for i in range(y_score.shape[1])])\n",
    "    elif method == 'precision':\n",
    "        return np.mean([metrics.precision_score(y_true[:,i], y_score[:,i]) for i in range(y_score.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words Representation\n",
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words representation\n",
    "vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_X_train = vectorizer.fit_transform(X_train)\n",
    "naive_X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape y_train and y_test\n",
    "y_train = np.array(list(y_train))\n",
    "y_test = np.array(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5124, 20)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = OneVsRestClassifier(MultinomialNB())\n",
    "nb.fit(naive_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy on Train : 0.5915300546448088\n",
      "Naive Bayes Accuracy on Test : 0.14508580343213728\n"
     ]
    }
   ],
   "source": [
    "naive_train_pred = nb.predict(naive_X_train)\n",
    "naive_test_pred = nb.predict(naive_X_test)\n",
    "print('Naive Bayes Accuracy on Train : {}'.format(metrics.accuracy_score(y_train, naive_train_pred)))\n",
    "print('Naive Bayes Accuracy on Test : {}'.format(metrics.accuracy_score(y_test, naive_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.37012637e-33,   4.31795630e-31,   3.59365748e-27,\n",
       "         2.63671879e-10,   1.11016946e-28,   1.01828361e-21,\n",
       "         3.29233909e-25,   1.31202345e-21,   0.00000000e+00,\n",
       "         1.39414154e-08,   1.33012783e-02,   4.52588102e-15,\n",
       "         8.36423998e-01,   3.23838390e-14,   1.86421000e-18,\n",
       "         3.69704282e-05,   8.66331663e-01,   9.99998836e-01,\n",
       "         9.93130417e-01,   8.06854819e-08])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict_proba(naive_X_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Avg Accuracy on test : 0.8982059282371295\n",
      "Naive Bayes Exact Accuracy on test : 0.14508580343213728\n",
      "Naive Bayes Precision on test : 0.6978311158754985\n",
      "Naive Bayes Recall on test : 0.4300237937094945\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Naive Bayes Avg Accuracy on test : {}'.format(score(y_test, naive_test_pred, 'avg')))\n",
    "print('Naive Bayes Exact Accuracy on test : {}'.format(score(y_test, naive_test_pred, 'exact')))\n",
    "print('Naive Bayes Precision on test : {}'.format(score(y_test, naive_test_pred, 'precision')))\n",
    "print('Naive Bayes Recall on test : {}'.format(score(y_test, naive_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy on Train : 0.7781030444964872\n",
      "Random Forest Accuracy on Test : 0.0514820592823713\n"
     ]
    }
   ],
   "source": [
    "rfc = OneVsRestClassifier(RandomForestClassifier())\n",
    "rfc.fit(naive_X_train, y_train)\n",
    "rfc_train_pred = rfc.predict(naive_X_train)\n",
    "rfc_test_pred = rfc.predict(naive_X_test)\n",
    "print('Random Forest Accuracy on Train : {}'.format(metrics.accuracy_score(y_train, rfc_train_pred)))\n",
    "print('Random Forest Accuracy on Test : {}'.format(metrics.accuracy_score(y_test, rfc_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Avg Accuracy on test : 0.869773790951638\n",
      "Random Forest Exact Accuracy on test : 0.0514820592823713\n",
      "Random Forest Precision on test : 0.7116486664026709\n",
      "Random Forest Recall on test : 0.17130686888834687\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Random Forest Avg Accuracy on test : {}'.format(score(y_test, rfc_test_pred, 'avg')))\n",
    "print('Random Forest Exact Accuracy on test : {}'.format(score(y_test, rfc_test_pred, 'exact')))\n",
    "print('Random Forest Precision on test : {}'.format(score(y_test, rfc_test_pred, 'precision')))\n",
    "print('Random Forest Recall on test : {}'.format(score(y_test, rfc_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"glove.6B.300d.txt\", \"rb\") as lines:\n",
    "    w2v = {line.decode(\"utf-8\").split()[0]: np.array(line.split()[1:]).astype(float)\n",
    "           for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = 300\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in re.sub('['+string.punctuation+']', '', words.strip()) if w in self.word2vec] or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "mean_embed = MeanEmbeddingVectorizer(w2v)\n",
    "glove_X_train = mean_embed.transform(X_train)\n",
    "glove_X_test = mean_embed.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5124, 300)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy on Train : 0.7090163934426229\n",
      "Random Forest Accuracy on Test : 0.014040561622464899\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier())\n",
    "rf.fit(glove_X_train, y_train)\n",
    "\n",
    "rf_train_pred = rf.predict(glove_X_train)\n",
    "rf_test_pred = rf.predict(glove_X_test)\n",
    "print('Random Forest Accuracy on Train : {}'.format(metrics.accuracy_score(y_train, rf_train_pred)))\n",
    "print('Random Forest Accuracy on Test : {}'.format(metrics.accuracy_score(y_test, rf_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Avg Accuracy on test : 0.8392745709828392\n",
      "Random Forest Exact Accuracy on test : 0.014040561622464899\n",
      "Random Forest Precision on test : 0.17422571214883256\n",
      "Random Forest Recall on test : 0.05759442981270631\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Random Forest Avg Accuracy on test : {}'.format(score(y_test, rf_test_pred, 'avg')))\n",
    "print('Random Forest Exact Accuracy on test : {}'.format(score(y_test, rf_test_pred, 'exact')))\n",
    "print('Random Forest Precision on test : {}'.format(score(y_test, rf_test_pred, 'precision')))\n",
    "print('Random Forest Recall on test : {}'.format(score(y_test, rf_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy on Train : 0.024785323965651834\n",
      "Logistic Regression Accuracy on Test : 0.033541341653666144\n"
     ]
    }
   ],
   "source": [
    "lr = OneVsRestClassifier(LogisticRegression())\n",
    "lr.fit(glove_X_train, y_train)\n",
    "\n",
    "lr_train_pred = lr.predict(glove_X_train)\n",
    "lr_test_pred = lr.predict(glove_X_test)\n",
    "print('Logistic Regression Accuracy on Train : {}'.format(metrics.accuracy_score(y_train, lr_train_pred)))\n",
    "print('Logistic Regression Accuracy on Test : {}'.format(metrics.accuracy_score(y_test, lr_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Avg Accuracy on test : 0.8517550702028079\n",
      "Logistic Regression Exact Accuracy on test : 0.033541341653666144\n",
      "Logistic Regression Precision on test : 0.13437848383500556\n",
      "Logistic Regression Recall on test : 0.04199852722650322\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Logistic Regression Avg Accuracy on test : {}'.format(score(y_test, lr_test_pred, 'avg')))\n",
    "print('Logistic Regression Exact Accuracy on test : {}'.format(score(y_test, lr_test_pred, 'exact')))\n",
    "print('Logistic Regression Precision on test : {}'.format(score(y_test, lr_test_pred, 'precision')))\n",
    "print('Logistic Regression Recall on test : {}'.format(score(y_test, lr_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Flatten\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in glove file\n",
    "embeddings_index = {}\n",
    "with open(\"glove.6B.300d.txt\", \"rb\") as f:\n",
    "    for line in f:\n",
    "        values = line.decode(\"utf-8\").split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = X_train.apply(lambda x: \n",
    "                            re.sub('['+string.punctuation+']', \n",
    "                                   '', x.strip())).values\n",
    "test_texts = X_test.apply(lambda x: \n",
    "                           re.sub('['+string.punctuation+']', \n",
    "                                  '', x.strip())).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "X_glove_train = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "X_glove_test = pad_sequences(test_sequences, \n",
    "                             maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build embedding matrix\n",
    "num_words = min(MAX_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5124/5124 [==============================] - 16s 3ms/step - loss: 0.3913 - acc: 0.8368\n",
      "Epoch 2/10\n",
      "5124/5124 [==============================] - 16s 3ms/step - loss: 0.3152 - acc: 0.8696\n",
      "Epoch 3/10\n",
      "5124/5124 [==============================] - 15s 3ms/step - loss: 0.2584 - acc: 0.8922\n",
      "Epoch 4/10\n",
      "5124/5124 [==============================] - 15s 3ms/step - loss: 0.2002 - acc: 0.9189\n",
      "Epoch 5/10\n",
      "5124/5124 [==============================] - 18s 4ms/step - loss: 0.1405 - acc: 0.9479\n",
      "Epoch 6/10\n",
      "5124/5124 [==============================] - 19s 4ms/step - loss: 0.0938 - acc: 0.9710\n",
      "Epoch 7/10\n",
      "5124/5124 [==============================] - 19s 4ms/step - loss: 0.0608 - acc: 0.9854\n",
      "Epoch 8/10\n",
      "5124/5124 [==============================] - 18s 4ms/step - loss: 0.0380 - acc: 0.9932\n",
      "Epoch 9/10\n",
      "5124/5124 [==============================] - 19s 4ms/step - loss: 0.0278 - acc: 0.9959\n",
      "Epoch 10/10\n",
      "5124/5124 [==============================] - 19s 4ms/step - loss: 0.0178 - acc: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12b909eb8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model = Sequential()\n",
    "e = Embedding(num_words, EMBEDDING_DIM, \n",
    "              weights=[embedding_matrix], \n",
    "              input_length=MAX_SEQUENCE_LENGTH, \n",
    "              trainable=False)\n",
    "model.add(e)\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_glove_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "nn_test_pred = model.predict(X_glove_test)\n",
    "nn_test_pred[nn_test_pred>0.5] = 1\n",
    "nn_test_pred[nn_test_pred<=0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Avg Accuracy on test : 0.8669656786271451\n",
      "Neural Network Exact Accuracy on test : 0.05226209048361934\n",
      "Neural Network Precision on test : 0.5231920016156562\n",
      "Neural Network Recall on test : 0.3205018980845515\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Neural Network Avg Accuracy on test : {}'.format(score(y_test, nn_test_pred, 'avg')))\n",
    "print('Neural Network Exact Accuracy on test : {}'.format(score(y_test, nn_test_pred, 'exact')))\n",
    "print('Neural Network Precision on test : {}'.format(score(y_test, nn_test_pred, 'precision')))\n",
    "print('Neural Network Recall on test : {}'.format(score(y_test, nn_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
