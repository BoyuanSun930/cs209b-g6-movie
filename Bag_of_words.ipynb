{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Final Project: Bag-of-Words Representation\n",
    "## Group Members: Jiacheng Shi, Boyuan Sun, Xiangru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import string\n",
    "import ast\n",
    "import re\n",
    "import warnings\n",
    "from meter import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "imdb_movie = pd.read_csv('data/imdb_multilabel.csv')\n",
    "\n",
    "# drop movies with unknown plot\n",
    "imdb_movie['plot'] = imdb_movie['plot'].apply(lambda sentence: 'drop' if (('plot ' in sentence.lower()) \n",
    "                                              and ('unknown' in sentence.lower()))\n",
    "                                              or (len(sentence.split()) < 100) \n",
    "                                              else sentence.lower())\n",
    "imdb_movie = imdb_movie[imdb_movie['plot'] != 'drop']\n",
    "\n",
    "# single-label encoding\n",
    "genre_dict = dict(zip(imdb_movie.genre.unique(), range(20)))\n",
    "genre_dict['sci-fi'] = 8\n",
    "imdb_movie['genre_code'] = imdb_movie.genre.replace(genre_dict).values\n",
    "\n",
    "# multi-label encoded as an array\n",
    "def multi_label_encoder(all_genre_list):\n",
    "    \"\"\" This function takes a list of genre with a dictionary that keeps track of the index of the genre\n",
    "    INPUTS\n",
    "    ------\n",
    "    all_genre_list: list of genres\n",
    "    genre_dict: dictionary of indexs\n",
    "    \n",
    "    OUTPUTS\n",
    "    -------\n",
    "    np array in {0, 1}\n",
    "    \"\"\"\n",
    "    encode = np.zeros(20)\n",
    "    all_genre_list = ast.literal_eval(all_genre_list)\n",
    "    for genre in all_genre_list:\n",
    "        if genre.lower() in genre_dict:\n",
    "            encode[genre_dict[genre.lower()]] = 1\n",
    "    return list(encode)\n",
    "\n",
    "imdb_movie['all_genre_encode'] = imdb_movie['all_genre'].apply(multi_label_encoder)\n",
    "imdb_movie['plot_list'] = imdb_movie['plot_list'].apply(ast.literal_eval)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imdb_movie['plot'], \n",
    "                                                    imdb_movie['all_genre_encode'],\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 209,\n",
    "                                                    stratify = imdb_movie['genre']\n",
    "                                                    )\n",
    "\n",
    "# reshape y_train and y_test\n",
    "y_train = np.array(list(y_train))\n",
    "y_test = np.array(list(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words representation\n",
    "vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_X_train = vectorizer.fit_transform(X_train)\n",
    "bag_X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3489, 20)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = OneVsRestClassifier(MultinomialNB())\n",
    "nb.fit(bag_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_train_pred = nb.predict(bag_X_train)\n",
    "naive_test_pred = nb.predict(bag_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.02587732e-26,   8.85694317e-34,   1.49873553e-23,\n",
       "         1.22586750e-22,   8.02465115e-22,   1.97463553e-16,\n",
       "         1.50755266e-28,   4.33454840e-25,   1.00000000e+00,\n",
       "         1.00233714e-11,   9.02363700e-16,   4.90038462e-15,\n",
       "         1.00000000e+00,   3.95075533e-22,   1.08958418e-15,\n",
       "         5.68696002e-11,   1.00000000e+00,   1.84119608e-14,\n",
       "         1.44924363e-02,   6.99786802e-11])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict_proba(bag_X_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Avg Accuracy on train : 0.9792777300085984\n",
      "Naive Bayes Exact Accuracy on train : 0.7179707652622528\n",
      "Naive Bayes Precision on train : 0.9315267823056468\n",
      "Naive Bayes Recall on train : 0.9288957083925142\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Naive Bayes Avg Accuracy on train : {}'.format(score(y_train, naive_train_pred, 'avg')))\n",
    "print('Naive Bayes Exact Accuracy on train : {}'.format(score(y_train, naive_train_pred, 'exact')))\n",
    "print('Naive Bayes Precision on train : {}'.format(score(y_train, naive_train_pred, 'precision')))\n",
    "print('Naive Bayes Recall on train : {}'.format(score(y_train, naive_train_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Avg Accuracy on test : 0.8965063001145475\n",
      "Naive Bayes Exact Accuracy on test : 0.13058419243986255\n",
      "Naive Bayes Precision on test : 0.7681719171017082\n",
      "Naive Bayes Recall on test : 0.4236525949790833\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Naive Bayes Avg Accuracy on test : {}'.format(score(y_test, naive_test_pred, 'avg')))\n",
    "print('Naive Bayes Exact Accuracy on test : {}'.format(score(y_test, naive_test_pred, 'exact')))\n",
    "print('Naive Bayes Precision on test : {}'.format(score(y_test, naive_test_pred, 'precision')))\n",
    "print('Naive Bayes Recall on test : {}'.format(score(y_test, naive_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filename = 'nb_bag.pkl'\n",
    "pickle.dump(nb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuning_parameters = {'estimator__n_estimators':[50, 100, 200], \n",
    "                        'estimator__max_depth':[100, 200, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier())\n",
    "rf = GridSearchCV(rf, param_grid = rf_tuning_parameters, cv=5, n_jobs=-1)\n",
    "rf.fit(bag_X_train, y_train)\n",
    "rf_train_pred = rf.predict(bag_X_train)\n",
    "rf_test_pred = rf.predict(bag_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__max_depth': 200, 'estimator__n_estimators': 100}"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Avg Accuracy on train : 0.9999570077386072\n",
      "Random Forest Exact Accuracy on train : 0.999140154772141\n",
      "Random Forest Precision on train : 1.0\n",
      "Random Forest Recall on train : 0.9993218893368867\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Random Forest Avg Accuracy on train : {}'.format(score(y_train, rf_train_pred, 'avg')))\n",
    "print('Random Forest Exact Accuracy on train : {}'.format(score(y_train, rf_train_pred, 'exact')))\n",
    "print('Random Forest Precision on train : {}'.format(score(y_train, rf_train_pred, 'precision')))\n",
    "print('Random Forest Recall on train : {}'.format(score(y_train, rf_train_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Avg Accuracy on test : 0.8701603665521191\n",
      "Random Forest Exact Accuracy on test : 0.05154639175257732\n",
      "Random Forest Precision on test : 0.672163815507625\n",
      "Random Forest Recall on test : 0.1545947643964105\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Random Forest Avg Accuracy on test : {}'.format(score(y_test, rf_test_pred, 'avg')))\n",
    "print('Random Forest Exact Accuracy on test : {}'.format(score(y_test, rf_test_pred, 'exact')))\n",
    "print('Random Forest Precision on test : {}'.format(score(y_test, rf_test_pred, 'precision')))\n",
    "print('Random Forest Recall on test : {}'.format(score(y_test, rf_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filename = 'rf_bag.pkl'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tuning_parameters = {'estimator__C': [5, 50, 100, 1000],\n",
    "                         'estimator__kernel': ['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = OneVsRestClassifier(SVC())\n",
    "svm = GridSearchCV(svm, param_grid = svm_tuning_parameters, cv=5, n_jobs=-1)\n",
    "svm.fit(bag_X_train, y_train)\n",
    "svm_train_pred = svm.predict(bag_X_train)\n",
    "svm_test_pred = svm.predict(bag_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 1000, 'estimator__kernel': 'rbf'}"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Avg Accuracy on train : 1.0\n",
      "SVM Exact Accuracy on train : 1.0\n",
      "SVM Precision on train : 1.0\n",
      "SVM Recall on train : 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('SVM Avg Accuracy on train : {}'.format(score(y_train, svm_train_pred, 'avg')))\n",
    "print('SVM Exact Accuracy on train : {}'.format(score(y_train, svm_train_pred, 'exact')))\n",
    "print('SVM Precision on train : {}'.format(score(y_train, svm_train_pred, 'precision')))\n",
    "print('SVM Recall on train : {}'.format(score(y_train, svm_train_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Avg Accuracy on test : 0.8882016036655211\n",
      "SVM Exact Accuracy on test : 0.09392898052691867\n",
      "SVM Precision on test : 0.6848130894195936\n",
      "SVM Recall on test : 0.49363130857564047\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('SVM Avg Accuracy on test : {}'.format(score(y_test, svm_test_pred, 'avg')))\n",
    "print('SVM Exact Accuracy on test : {}'.format(score(y_test, svm_test_pred, 'exact')))\n",
    "print('SVM Precision on test : {}'.format(score(y_test, svm_test_pred, 'precision')))\n",
    "print('SVM Recall on test : {}'.format(score(y_test, svm_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filename = 'svm_bag.pkl'\n",
    "pickle.dump(svm, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = OneVsRestClassifier(LogisticRegressionCV(cv = 5))\n",
    "lr.fit(bag_X_train, y_train)\n",
    "lr_train_pred = lr.predict(bag_X_train)\n",
    "lr_test_pred = lr.predict(bag_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Avg Accuracy on train : 0.9929492691315562\n",
      "Logistic Regression Exact Accuracy on train : 0.8747492118085411\n",
      "Logistic Regression Precision on train : 0.9950027359503879\n",
      "Logistic Regression Recall on train : 0.9822574263121329\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Logistic Regression Avg Accuracy on train : {}'.format(score(y_train, lr_train_pred, 'avg')))\n",
    "print('Logistic Regression Exact Accuracy on train : {}'.format(score(y_train, lr_train_pred, 'exact')))\n",
    "print('Logistic Regression Precision on train : {}'.format(score(y_train, lr_train_pred, 'precision')))\n",
    "print('Logistic Regression Recall on train : {}'.format(score(y_train, lr_train_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Avg Accuracy on test : 0.8963917525773195\n",
      "Logistic Regression Exact Accuracy on test : 0.11798396334478808\n",
      "Logistic Regression Precision on test : 0.7402333343216527\n",
      "Logistic Regression Recall on test : 0.46579822650702135\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Logistic Regression Avg Accuracy on test : {}'.format(score(y_test, lr_test_pred, 'avg')))\n",
    "print('Logistic Regression Exact Accuracy on test : {}'.format(score(y_test, lr_test_pred, 'exact')))\n",
    "print('Logistic Regression Precision on test : {}'.format(score(y_test, lr_test_pred, 'precision')))\n",
    "print('Logistic Regression Recall on test : {}'.format(score(y_test, lr_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filename = 'lr_bag.pkl'\n",
    "pickle.dump(lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
