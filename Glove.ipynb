{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Final Project : Glove\n",
    "### Group Members : Jiachang Shi, Boyuan Sun, Xiangru Shu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import string\n",
    "import ast\n",
    "import re\n",
    "import warnings\n",
    "from meter import *\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Flatten, LSTM, Dropout, RNN\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Proprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "imdb_movie = pd.read_csv('data/imdb_multilabel.csv')\n",
    "\n",
    "# drop movies with unknown plot\n",
    "imdb_movie['plot'] = imdb_movie['plot'].apply(lambda sentence: 'drop' if (('plot ' in sentence.lower()) \n",
    "                                              and ('unknown' in sentence.lower()))\n",
    "                                              or (len(sentence.split()) < 100) \n",
    "                                              else sentence)\n",
    "imdb_movie = imdb_movie[imdb_movie['plot'] != 'drop']\n",
    "\n",
    "# single-label encoding\n",
    "genre_dict = dict(zip(imdb_movie.genre.unique(), range(20)))\n",
    "genre_dict['sci-fi'] = 8\n",
    "imdb_movie['genre_code'] = imdb_movie.genre.replace(genre_dict).values\n",
    "\n",
    "# multi-label encoded as an array\n",
    "def multi_label_encoder(all_genre_list):\n",
    "    \"\"\" This function takes a list of genre with a dictionary that keeps track of the index of the genre\n",
    "    INPUTS\n",
    "    ------\n",
    "    all_genre_list: list of genres\n",
    "    genre_dict: dictionary of indexs\n",
    "    \n",
    "    OUTPUTS\n",
    "    -------\n",
    "    np array in {0, 1}\n",
    "    \"\"\"\n",
    "    encode = np.zeros(20)\n",
    "    all_genre_list = ast.literal_eval(all_genre_list)\n",
    "    for genre in all_genre_list:\n",
    "        if genre.lower() in genre_dict:\n",
    "            encode[genre_dict[genre.lower()]] = 1\n",
    "    return list(encode)\n",
    "\n",
    "imdb_movie['all_genre_encode'] = imdb_movie['all_genre'].apply(multi_label_encoder)\n",
    "imdb_movie['plot_list'] = imdb_movie['plot_list'].apply(ast.literal_eval)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imdb_movie['plot'], \n",
    "                                                    imdb_movie['all_genre_encode'],\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 209,\n",
    "                                                    stratify = imdb_movie['genre'],\n",
    "                                                    shuffle = True\n",
    "                                                    )\n",
    "\n",
    "# reshape y_train and y_test\n",
    "y_train = np.array(list(y_train))\n",
    "y_test = np.array(list(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Glove Representation of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"glove.6B.300d.txt\", \"rb\") as lines:\n",
    "    w2v = {line.decode(\"utf-8\").split()[0]: np.array(line.split()[1:]).astype(float)\n",
    "           for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = 300\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in re.sub('['+string.punctuation+']', '', words.strip()) if w in self.word2vec] or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "mean_embed = MeanEmbeddingVectorizer(w2v)\n",
    "glove_X_train = mean_embed.transform(X_train)\n",
    "glove_X_test = mean_embed.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# class TfidfEmbeddingVectorizer(object):\n",
    "#     def __init__(self, word2vec):\n",
    "#         self.word2vec = word2vec\n",
    "#         self.word2weight = None\n",
    "#         self.dim = 300\n",
    "\n",
    "#     def fit(self, X):\n",
    "#         tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "#         tfidf.fit(X)\n",
    "#         # if a word was never seen - it must be at least as infrequent\n",
    "#         # as any of the known words - so the default idf is the max of \n",
    "#         # known idf's\n",
    "#         max_idf = max(tfidf.idf_)\n",
    "#         self.word2weight = defaultdict(\n",
    "#             lambda: max_idf,\n",
    "#             [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         return np.array([\n",
    "#                 np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "#                          for w in words if w in self.word2vec] or\n",
    "#                         [np.zeros(self.dim)], axis=0)\n",
    "#                 for words in X\n",
    "#             ])\n",
    "    \n",
    "# tf_embed = TfidfEmbeddingVectorizer(w2v)\n",
    "# tf_embed.fit(X_train)\n",
    "# glove_X_train = tf_embed.transform(X_train)\n",
    "# glove_X_test = tf_embed.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3489, 300)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier())\n",
    "rf.fit(glove_X_train, y_train)\n",
    "\n",
    "rf_train_pred = rf.predict(glove_X_train)\n",
    "rf_test_pred = rf.predict(glove_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Avg Accuracy on train : 0.9825738033820578\n",
      "Random Forest Exact Accuracy on train : 0.707079392376039\n",
      "Random Forest Precision on train : 0.9991640440168593\n",
      "Random Forest Recall on train : 0.849986741459887\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Random Forest Avg Accuracy on train : {}'.format(score(y_train, rf_train_pred, 'avg')))\n",
    "print('Random Forest Exact Accuracy on train : {}'.format(score(y_train, rf_train_pred, 'exact')))\n",
    "print('Random Forest Precision on train : {}'.format(score(y_train, rf_train_pred, 'precision')))\n",
    "print('Random Forest Recall on train : {}'.format(score(y_train, rf_train_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Avg Accuracy on test : 0.8313287514318443\n",
      "Random Forest Exact Accuracy on test : 0.014891179839633447\n",
      "Random Forest Precision on test : 0.25802607561588775\n",
      "Random Forest Recall on test : 0.06957369331005318\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Random Forest Avg Accuracy on test : {}'.format(score(y_test, rf_test_pred, 'avg')))\n",
    "print('Random Forest Exact Accuracy on test : {}'.format(score(y_test, rf_test_pred, 'exact')))\n",
    "print('Random Forest Precision on test : {}'.format(score(y_test, rf_test_pred, 'precision')))\n",
    "print('Random Forest Recall on test : {}'.format(score(y_test, rf_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = OneVsRestClassifier(LogisticRegressionCV(cv = 5))\n",
    "lr.fit(glove_X_train, y_train)\n",
    "lr_train_pred = lr.predict(glove_X_train)\n",
    "lr_test_pred = lr.predict(glove_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Avg Accuracy on train : 0.850902837489252\n",
      "Logistic Regression Exact Accuracy on train : 0.025508741759816565\n",
      "Logistic Regression Precision on train : 0.49102516368430926\n",
      "Logistic Regression Recall on train : 0.06456805635475486\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Logistic Regression Avg Accuracy on train : {}'.format(score(y_train, lr_train_pred, 'avg')))\n",
    "print('Logistic Regression Exact Accuracy on train : {}'.format(score(y_train, lr_train_pred, 'exact')))\n",
    "print('Logistic Regression Precision on train : {}'.format(score(y_train, lr_train_pred, 'precision')))\n",
    "print('Logistic Regression Recall on train : {}'.format(score(y_train, lr_train_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Avg Accuracy on test : 0.8460481099656357\n",
      "Logistic Regression Exact Accuracy on test : 0.024054982817869417\n",
      "Logistic Regression Precision on test : 0.2552112387653064\n",
      "Logistic Regression Recall on test : 0.059678851243138896\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Logistic Regression Avg Accuracy on test : {}'.format(score(y_test, lr_test_pred, 'avg')))\n",
    "print('Logistic Regression Exact Accuracy on test : {}'.format(score(y_test, lr_test_pred, 'exact')))\n",
    "print('Logistic Regression Precision on test : {}'.format(score(y_test, lr_test_pred, 'precision')))\n",
    "print('Logistic Regression Recall on test : {}'.format(score(y_test, lr_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_tuning_parameters = {'estimator__C': [5, 50, 100, 1000],\n",
    "                         'estimator__kernel': ['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on Train : 0.431303669008587\n",
      "SVM Accuracy on Test : 0.08580343213728549\n"
     ]
    }
   ],
   "source": [
    "svm = OneVsRestClassifier(SVC())\n",
    "svm = GridSearchCV(svm, param_grid = svm_tuning_parameters, cv=5, n_jobs=-1)\n",
    "svm.fit(glove_X_train, y_train)\n",
    "svm_train_pred = svm.predict(glove_X_train)\n",
    "svm_test_pred = svm.predict(glove_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 100, 'estimator__kernel': 'rbf'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Avg Accuracy on train : 0.932211163153786\n",
      "SVM Exact Accuracy on train : 0.431303669008587\n",
      "SVM Precision on train : 0.938492996003603\n",
      "SVM Recall on train : 0.4921213354419586\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('SVM Avg Accuracy on train : {}'.format(score(y_train, svm_train_pred, 'avg')))\n",
    "print('SVM Exact Accuracy on train : {}'.format(score(y_train, svm_train_pred, 'exact')))\n",
    "print('SVM Precision on train : {}'.format(score(y_train, svm_train_pred, 'precision')))\n",
    "print('SVM Recall on train : {}'.format(score(y_train, svm_train_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Avg Accuracy on test : 0.8849453978159126\n",
      "SVM Exact Accuracy on test : 0.08580343213728549\n",
      "SVM Precision on test : 0.7342857827952918\n",
      "SVM Recall on test : 0.28096075952803456\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('SVM Avg Accuracy on test : {}'.format(score(y_test, svm_test_pred, 'avg')))\n",
    "print('SVM Exact Accuracy on test : {}'.format(score(y_test, svm_test_pred, 'exact')))\n",
    "print('SVM Precision on test : {}'.format(score(y_test, svm_test_pred, 'precision')))\n",
    "print('SVM Recall on test : {}'.format(score(y_test, svm_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "print('SVM Avg Accuracy on test : {}'.format(score(y_test, svm_test_pred, 'avg')))\n",
    "print('SVM Exact Accuracy on test : {}'.format(score(y_test, svm_test_pred, 'exact')))\n",
    "print('SVM Precision on test : {}'.format(score(y_test, svm_test_pred, 'precision')))\n",
    "print('SVM Recall on test : {}'.format(score(y_test, svm_test_pred, 'recall')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(\"glove.6B.300d.txt\", \"rb\") as f:\n",
    "    for line in f:\n",
    "        values = line.decode(\"utf-8\").split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAX_WORDS = 40000\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_texts = X_train.apply(lambda x: \n",
    "                            re.sub('['+string.punctuation+']', \n",
    "                                   '', x.strip())).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "X_glove_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "test_texts = X_test.apply(lambda x: \n",
    "                           re.sub('['+string.punctuation+']', \n",
    "                                  '', x.strip())).values\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "X_glove_test = pad_sequences(test_sequences, \n",
    "                             maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "#     if i >= MAX_WORDS:\n",
    "#         continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3489, 300)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_glove_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('embedding_matrix.npy', embedding_matrix)\n",
    "np.save('X_glove_train.npy', X_glove_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('X_glove_test.npy', X_glove_test)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.load('embedding_matrix.npy')\n",
    "X_glove_train = np.load('X_glove_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "X_glove_test = np.load('X_glove_test.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAX_WORDS = 40000\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 44984"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "e = Embedding(num_words, EMBEDDING_DIM, \n",
    "              weights=[embedding_matrix], \n",
    "              input_length=MAX_SEQUENCE_LENGTH, \n",
    "              trainable=False)\n",
    "model.add(e)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0005), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3489 samples, validate on 873 samples\n",
      "Epoch 1/20\n",
      "1472/3489 [===========>..................] - ETA: 5s - loss: 0.4934 - acc: 0.7963"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-9ff3526ead6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(X_glove_train, y_train,\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs=20, validation_data = (X_glove_test, y_test))\n\u001b[0m",
      "\u001b[0;32m/Users/jerrysun/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/jerrysun/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/jerrysun/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jerrysun/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jerrysun/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jerrysun/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jerrysun/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jerrysun/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jerrysun/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_glove_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=20, validation_data = (X_glove_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_glove_test = model.predict(X_glove_test)\n",
    "pred_glove_train = model.predict(X_glove_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVE Embedding Accuracy on train : 1.0\n",
      "GloVE Embedding Exact Accuracy on train : 1.0\n",
      "GloVE Embedding Precision on train : 1.0\n",
      "GloVE Embedding Recall on train : 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('GloVE Embedding Accuracy on train : {}'.format(score_thres(y_train, pred_glove_train, method='avg')))\n",
    "print('GloVE Embedding Exact Accuracy on train : {}'.format(score_thres(y_train, pred_glove_train, method='exact')))\n",
    "print('GloVE Embedding Precision on train : {}'.format(score_thres(y_train, pred_glove_train, method='precision')))\n",
    "print('GloVE Embedding Recall on train : {}'.format(score_thres(y_train, pred_glove_train, method='recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVE Embedding Accuracy on test : 0.8747422680412372\n",
      "GloVE Embedding Exact Accuracy on test : 0.06872852233676977\n",
      "GloVE Embedding Precision on test : 0.5830024639655649\n",
      "GloVE Embedding Recall on test : 0.3606915678387714\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('GloVE Embedding Accuracy on test : {}'.format(score_thres(y_test, pred_glove_test, method='avg')))\n",
    "print('GloVE Embedding Exact Accuracy on test : {}'.format(score_thres(y_test, pred_glove_test, method='exact')))\n",
    "print('GloVE Embedding Precision on test : {}'.format(score_thres(y_test, pred_glove_test, method='precision')))\n",
    "print('GloVE Embedding Recall on test : {}'.format(score_thres(y_test, pred_glove_test, method='recall')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "e = Embedding(num_words, EMBEDDING_DIM, \n",
    "              weights=[embedding_matrix], \n",
    "              input_length=MAX_SEQUENCE_LENGTH, \n",
    "              trainable=False)\n",
    "lstm.add(e)\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Conv1D(32, 5, activation='relu'))\n",
    "lstm.add(LSTM(100, recurrent_dropout=0.2))\n",
    "lstm.add(Dense(20, activation='sigmoid'))\n",
    "# compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 300)          12000000  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 96, 32)            48032     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                2020      \n",
      "=================================================================\n",
      "Total params: 12,103,252\n",
      "Trainable params: 103,252\n",
      "Non-trainable params: 12,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3489 samples, validate on 873 samples\n",
      "Epoch 1/20\n",
      "3489/3489 [==============================] - 7s 2ms/step - loss: 0.5205 - acc: 0.7933 - val_loss: 0.4033 - val_acc: 0.8404\n",
      "Epoch 2/20\n",
      "3489/3489 [==============================] - 7s 2ms/step - loss: 0.3932 - acc: 0.8426 - val_loss: 0.3948 - val_acc: 0.8404\n",
      "Epoch 3/20\n",
      "3489/3489 [==============================] - 6s 2ms/step - loss: 0.3908 - acc: 0.8428 - val_loss: 0.3941 - val_acc: 0.8404\n",
      "Epoch 4/20\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.3898 - acc: 0.8431 - val_loss: 0.3934 - val_acc: 0.8409\n",
      "Epoch 5/20\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.3882 - acc: 0.8438 - val_loss: 0.3914 - val_acc: 0.8423\n",
      "Epoch 6/20\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.3838 - acc: 0.8448 - val_loss: 0.3814 - val_acc: 0.8447\n",
      "Epoch 7/20\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.3752 - acc: 0.8471 - val_loss: 0.3755 - val_acc: 0.8458\n",
      "Epoch 8/20\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.3690 - acc: 0.8496 - val_loss: 0.3691 - val_acc: 0.8471\n",
      "Epoch 9/20\n",
      "3489/3489 [==============================] - 6s 2ms/step - loss: 0.3613 - acc: 0.8522 - val_loss: 0.3586 - val_acc: 0.8502\n",
      "Epoch 10/20\n",
      "3489/3489 [==============================] - 6s 2ms/step - loss: 0.3513 - acc: 0.8561 - val_loss: 0.3519 - val_acc: 0.8549\n",
      "Epoch 11/20\n",
      "3489/3489 [==============================] - 7s 2ms/step - loss: 0.3475 - acc: 0.8570 - val_loss: 0.3438 - val_acc: 0.8562\n",
      "Epoch 12/20\n",
      "3489/3489 [==============================] - 7s 2ms/step - loss: 0.3389 - acc: 0.8596 - val_loss: 0.3391 - val_acc: 0.8592\n",
      "Epoch 13/20\n",
      "3489/3489 [==============================] - 6s 2ms/step - loss: 0.3313 - acc: 0.8623 - val_loss: 0.3340 - val_acc: 0.8608\n",
      "Epoch 14/20\n",
      "3489/3489 [==============================] - 6s 2ms/step - loss: 0.3250 - acc: 0.8657 - val_loss: 0.3284 - val_acc: 0.8626\n",
      "Epoch 15/20\n",
      "3489/3489 [==============================] - 6s 2ms/step - loss: 0.3195 - acc: 0.8667 - val_loss: 0.3236 - val_acc: 0.8646\n",
      "Epoch 16/20\n",
      "3489/3489 [==============================] - 7s 2ms/step - loss: 0.3151 - acc: 0.8681 - val_loss: 0.3213 - val_acc: 0.8645\n",
      "Epoch 17/20\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.3109 - acc: 0.8693 - val_loss: 0.3135 - val_acc: 0.8670\n",
      "Epoch 18/20\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.3094 - acc: 0.8705 - val_loss: 0.3154 - val_acc: 0.8686\n",
      "Epoch 19/20\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.3017 - acc: 0.8739 - val_loss: 0.3110 - val_acc: 0.8694\n",
      "Epoch 20/20\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.2984 - acc: 0.8750 - val_loss: 0.3073 - val_acc: 0.8711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3183fa58>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.compile(optimizer=Adam(lr=0.0005), loss='binary_crossentropy', metrics=['acc'])\n",
    "lstm.fit(X_glove_train, y_train, validation_data= (X_glove_test, y_test),\n",
    "          batch_size=128,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Embedding Accuracy on test : 0.8847877358490567\n",
      "LSTM Embedding Exact Accuracy on test : 0.09355345911949685\n",
      "LSTM Embedding Precision on test : 0.5810460229570971\n",
      "LSTM Embedding Recall on test : 0.4279486141494283\n"
     ]
    }
   ],
   "source": [
    "lstm_pred_glove_test = lstm.predict(X_glove_test)\n",
    "# evaluation\n",
    "print('LSTM Embedding Accuracy on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='avg')))\n",
    "print('LSTM Embedding Exact Accuracy on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='exact')))\n",
    "print('LSTM Embedding Precision on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='precision')))\n",
    "print('LSTM Embedding Recall on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='recall')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_glove = Sequential()\n",
    "e = Embedding(num_words, EMBEDDING_DIM, \n",
    "              weights=[embedding_matrix], \n",
    "              input_length=MAX_SEQUENCE_LENGTH, \n",
    "              trainable=False)\n",
    "lstm_glove.add(e)\n",
    "lstm_glove.add(LSTM(100, dropout = 0.2, recurrent_dropout=0.2))\n",
    "lstm_glove.add(Dense(20, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 100, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 20)                2020      \n",
      "=================================================================\n",
      "Total params: 6,162,420\n",
      "Trainable params: 162,420\n",
      "Non-trainable params: 6,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_glove.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_glove.compile(optimizer=Adam(lr=0.0005), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5084 samples, validate on 1272 samples\n",
      "Epoch 1/20\n",
      "5084/5084 [==============================] - 9s 2ms/step - loss: 0.1810 - acc: 0.9258 - val_loss: 0.2624 - val_acc: 0.8906\n",
      "Epoch 2/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1789 - acc: 0.9267 - val_loss: 0.2633 - val_acc: 0.8906\n",
      "Epoch 3/20\n",
      "5084/5084 [==============================] - 10s 2ms/step - loss: 0.1772 - acc: 0.9283 - val_loss: 0.2634 - val_acc: 0.8911\n",
      "Epoch 4/20\n",
      "5084/5084 [==============================] - 10s 2ms/step - loss: 0.1739 - acc: 0.9289 - val_loss: 0.2659 - val_acc: 0.8903\n",
      "Epoch 5/20\n",
      "5084/5084 [==============================] - 9s 2ms/step - loss: 0.1711 - acc: 0.9314 - val_loss: 0.2658 - val_acc: 0.8895\n",
      "Epoch 6/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1692 - acc: 0.9317 - val_loss: 0.2665 - val_acc: 0.8908\n",
      "Epoch 7/20\n",
      "5084/5084 [==============================] - 9s 2ms/step - loss: 0.1661 - acc: 0.9329 - val_loss: 0.2676 - val_acc: 0.8895\n",
      "Epoch 8/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1649 - acc: 0.9333 - val_loss: 0.2683 - val_acc: 0.8903\n",
      "Epoch 9/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1616 - acc: 0.9356 - val_loss: 0.2699 - val_acc: 0.8906\n",
      "Epoch 10/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1612 - acc: 0.9360 - val_loss: 0.2709 - val_acc: 0.8903\n",
      "Epoch 11/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1575 - acc: 0.9381 - val_loss: 0.2702 - val_acc: 0.8914\n",
      "Epoch 12/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1562 - acc: 0.9381 - val_loss: 0.2716 - val_acc: 0.8900\n",
      "Epoch 13/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1543 - acc: 0.9389 - val_loss: 0.2732 - val_acc: 0.8891\n",
      "Epoch 14/20\n",
      "5084/5084 [==============================] - 9s 2ms/step - loss: 0.1521 - acc: 0.9402 - val_loss: 0.2732 - val_acc: 0.8899\n",
      "Epoch 15/20\n",
      "5084/5084 [==============================] - 9s 2ms/step - loss: 0.1502 - acc: 0.9410 - val_loss: 0.2756 - val_acc: 0.8898\n",
      "Epoch 16/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1478 - acc: 0.9419 - val_loss: 0.2778 - val_acc: 0.8894\n",
      "Epoch 17/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1463 - acc: 0.9431 - val_loss: 0.2779 - val_acc: 0.8882\n",
      "Epoch 18/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1438 - acc: 0.9439 - val_loss: 0.2780 - val_acc: 0.8880\n",
      "Epoch 19/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1410 - acc: 0.9449 - val_loss: 0.2800 - val_acc: 0.8891\n",
      "Epoch 20/20\n",
      "5084/5084 [==============================] - 8s 2ms/step - loss: 0.1397 - acc: 0.9464 - val_loss: 0.2830 - val_acc: 0.8892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a9e723080>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_glove.fit(X_glove_train, y_train, validation_data= (X_glove_test, y_test),\n",
    "          batch_size=128,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-73e230041ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm_pred_glove_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_glove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_glove_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM Embedding Accuracy on test : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_thres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_pred_glove_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM Embedding Exact Accuracy on test : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_thres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_pred_glove_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'exact'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM Embedding Precision on test : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_thres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_pred_glove_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm_glove' is not defined"
     ]
    }
   ],
   "source": [
    "lstm_pred_glove_test = lstm_glove.predict(X_glove_test)\n",
    "# evaluation\n",
    "print('LSTM Embedding Accuracy on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='avg')))\n",
    "print('LSTM Embedding Exact Accuracy on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='exact')))\n",
    "print('LSTM Embedding Precision on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='precision')))\n",
    "print('LSTM Embedding Recall on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='recall')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM - 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_glove_2layers = Sequential()\n",
    "e = Embedding(num_words, EMBEDDING_DIM, \n",
    "              weights=[embedding_matrix], \n",
    "              input_length=MAX_SEQUENCE_LENGTH, \n",
    "              trainable=False)\n",
    "lstm_glove_2layers.add(e)\n",
    "#lstm_glove_2layers.add(LSTM(200, dropout = 0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "lstm_glove_2layers.add(LSTM(200, dropout = 0.2, recurrent_dropout=0.2))\n",
    "lstm_glove_2layers.add(Dense(20, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_glove.compile(optimizer=Adam(lr=0.0005), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### load test\n",
    "from keras.models import load_model\n",
    "load_model = load_model('lstm_glove_68_51') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Embedding Accuracy on test : 0.8899198167239404\n",
      "LSTM Embedding Exact Accuracy on test : 0.11798396334478808\n",
      "LSTM Embedding Precision on test : 0.6867441944938573\n",
      "LSTM Embedding Recall on test : 0.5190011893170453\n"
     ]
    }
   ],
   "source": [
    "lstm_pred_glove_test = load_model.predict(X_glove_test)\n",
    "# evaluation\n",
    "print('LSTM Embedding Accuracy on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='avg')))\n",
    "print('LSTM Embedding Exact Accuracy on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='exact')))\n",
    "print('LSTM Embedding Precision on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='precision')))\n",
    "print('LSTM Embedding Recall on test : {}'.format(score_thres(y_test, lstm_pred_glove_test, method='recall')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
