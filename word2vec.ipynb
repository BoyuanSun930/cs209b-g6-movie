{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import string\n",
    "import ast\n",
    "import re\n",
    "import warnings\n",
    "from meter import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Flatten, LSTM\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "imdb_movie = pd.read_csv('data/imdb_multilabel.csv')\n",
    "\n",
    "# drop movies with unknown plot\n",
    "imdb_movie['plot'] = imdb_movie['plot'].apply(lambda sentence: 'drop' if (('plot ' in sentence.lower()) \n",
    "                                              and ('unknown' in sentence.lower()))\n",
    "                                              or (len(sentence.split()) < 100) \n",
    "                                              else sentence)\n",
    "imdb_movie = imdb_movie[imdb_movie['plot'] != 'drop']\n",
    "\n",
    "# single-label encoding\n",
    "genre_dict = dict(zip(imdb_movie.genre.unique(), range(20)))\n",
    "genre_dict['sci-fi'] = 8\n",
    "imdb_movie['genre_code'] = imdb_movie.genre.replace(genre_dict).values\n",
    "\n",
    "# multi-label encoded as an array\n",
    "def multi_label_encoder(all_genre_list):\n",
    "    \"\"\" This function takes a list of genre with a dictionary that keeps track of the index of the genre\n",
    "    INPUTS\n",
    "    ------\n",
    "    all_genre_list: list of genres\n",
    "    genre_dict: dictionary of indexs\n",
    "    \n",
    "    OUTPUTS\n",
    "    -------\n",
    "    np array in {0, 1}\n",
    "    \"\"\"\n",
    "    encode = np.zeros(20)\n",
    "    all_genre_list = ast.literal_eval(all_genre_list)\n",
    "    for genre in all_genre_list:\n",
    "        if genre.lower() in genre_dict:\n",
    "            encode[genre_dict[genre.lower()]] = 1\n",
    "    return list(encode)\n",
    "\n",
    "imdb_movie['all_genre_encode'] = imdb_movie['all_genre'].apply(multi_label_encoder)\n",
    "imdb_movie['plot_list'] = imdb_movie['plot_list'].apply(ast.literal_eval)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imdb_movie['plot'], \n",
    "                                                    imdb_movie['all_genre_encode'],\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 209,\n",
    "                                                    stratify = imdb_movie['genre'],\n",
    "                                                    shuffle = True\n",
    "                                                    )\n",
    "\n",
    "# reshape y_train and y_test\n",
    "y_train = np.array(list(y_train))\n",
    "y_test = np.array(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 200\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_matrix = np.load('w2v_matrix.npy')\n",
    "X_w2v_train = np.load('X_w2v_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "X_w2v_test = np.load('X_w2v_test.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU data preprocessing (don't rerun the following part on JupyterHub)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = X_train.apply(lambda x: \n",
    "                            re.sub('['+string.punctuation+']', \n",
    "                                   '', x.strip())).values\n",
    "test_texts = X_test.apply(lambda x: \n",
    "                          re.sub('['+string.punctuation+']', \n",
    "                                 '', x.strip())).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec([t.split() for t in train_texts], size=EMBEDDING_DIM, min_count=1)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "word_index = tokenizer.word_index\n",
    "num_words = len(word_index) + 1\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "X_w2v_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "X_w2v_test = pad_sequences(test_sequences, \n",
    "                             maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_vector = w2v_model.wv[word]\n",
    "    else:\n",
    "        embedding_vector = 0\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        w2v_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('w2v_matrix.npy', w2v_matrix)\n",
    "np.save('X_w2v_train.npy', X_w2v_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('X_w2v_test.npy', X_w2v_test)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models - Mean of word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = EMBEDDING_DIM\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in re.sub('['+string.punctuation+']', '', words.strip()) if w in self.word2vec] or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "mean_embed = MeanEmbeddingVectorizer(w2v_model.wv)\n",
    "word2vec_X_train = mean_embed.transform(X_train)\n",
    "word2vec_X_test = mean_embed.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3489, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_tuning_parameters = {'estimator__n_estimators':[50, 100, 200], \n",
    "                        'estimator__max_depth':[100, 200, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          n_jobs=1),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'estimator__n_estimators': [50, 100, 200], 'estimator__max_depth': [100, 200, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier())\n",
    "rf = GridSearchCV(rf, param_grid = rf_tuning_parameters, cv=5, n_jobs=-1)\n",
    "rf.fit(word2vec_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__max_depth': 200, 'estimator__n_estimators': 200}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filename = 'rf_w2v.pkl'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_rf = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_train_pred = loaded_rf.predict(word2vec_X_train)\n",
    "rf_test_pred = loaded_rf.predict(word2vec_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Avg Accuracy on train : 1.0\n",
      "Random Forest Exact Accuracy on train : 1.0\n",
      "Random Forest Precision on train : 1.0\n",
      "Random Forest Recall on train : 1.0\n",
      "Random Forest Hit Rate on train : 1.0\n",
      "Random Forest F1 Score on train : 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Random Forest Avg Accuracy on train : {}'.format(score(y_train, rf_train_pred, 'avg')))\n",
    "print('Random Forest Exact Accuracy on train : {}'.format(score(y_train, rf_train_pred, 'exact')))\n",
    "print('Random Forest Precision on train : {}'.format(score(y_train, rf_train_pred, 'precision')))\n",
    "print('Random Forest Recall on train : {}'.format(score(y_train, rf_train_pred, 'recall')))\n",
    "print('Random Forest Hit Rate on train : {}'.format(score(y_train, rf_train_pred, 'hit')))\n",
    "print('Random Forest F1 Score on train : {}'.format(score(y_train, rf_train_pred, 'f1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Avg Accuracy on test : 0.8361970217640321\n",
      "Random Forest Exact Accuracy on test : 0.013745704467353952\n",
      "Random Forest Precision on test : 0.1545772624185405\n",
      "Random Forest Recall on test : 0.050955823328328154\n",
      "Random Forest Hit Rate on test : 0.40778923253150057\n",
      "Random Forest F1 Score on test : 0.07664568111507343\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Random Forest Avg Accuracy on test : {}'.format(score(y_test, rf_test_pred, 'avg')))\n",
    "print('Random Forest Exact Accuracy on test : {}'.format(score(y_test, rf_test_pred, 'exact')))\n",
    "print('Random Forest Precision on test : {}'.format(score(y_test, rf_test_pred, 'precision')))\n",
    "print('Random Forest Recall on test : {}'.format(score(y_test, rf_test_pred, 'recall')))\n",
    "print('Random Forest Hit Rate on test : {}'.format(score(y_test, rf_test_pred, 'hit')))\n",
    "print('Random Forest F1 Score on test : {}'.format(score(y_test, rf_test_pred, 'f1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = OneVsRestClassifier(LogisticRegressionCV(cv = 5))\n",
    "lr.fit(word2vec_X_train, y_train)\n",
    "lr_train_pred = lr.predict(word2vec_X_train)\n",
    "lr_test_pred = lr.predict(word2vec_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "filename = 'lr_w2v.pkl'\n",
    "pickle.dump(lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_lr = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Avg Accuracy on train : 0.8476784178847807\n",
      "Logistic Regression Exact Accuracy on train : 0.022069360848380626\n",
      "Logistic Regression Precision on train : 0.17117753447775025\n",
      "Logistic Regression Recall on train : 0.038822209695275486\n",
      "Logistic Regression Hit Rate on train : 0.4044138721696761\n",
      "Logistic Regression F1 Score on train : 0.06329045937446505\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Logistic Regression Avg Accuracy on train : {}'.format(score(y_train, lr_train_pred, 'avg')))\n",
    "print('Logistic Regression Exact Accuracy on train : {}'.format(score(y_train, lr_train_pred, 'exact')))\n",
    "print('Logistic Regression Precision on train : {}'.format(score(y_train, lr_train_pred, 'precision')))\n",
    "print('Logistic Regression Recall on train : {}'.format(score(y_train, lr_train_pred, 'recall')))\n",
    "print('Logistic Regression Hit Rate on train : {}'.format(score(y_train,lr_train_pred, 'hit')))\n",
    "print('Logistic Regression F1 Score on train : {}'.format(score(y_train, lr_train_pred, 'f1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Avg Accuracy on test : 0.8456471935853379\n",
      "Logistic Regression Exact Accuracy on test : 0.018327605956471937\n",
      "Logistic Regression Precision on test : 0.05637432188065099\n",
      "Logistic Regression Recall on test : 0.039566905309413196\n",
      "Logistic Regression Hit Rate on test : 0.4066437571592211\n",
      "Logistic Regression F1 Score on test : 0.04649841410336052\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('Logistic Regression Avg Accuracy on test : {}'.format(score(y_test, lr_test_pred, 'avg')))\n",
    "print('Logistic Regression Exact Accuracy on test : {}'.format(score(y_test, lr_test_pred, 'exact')))\n",
    "print('Logistic Regression Precision on test : {}'.format(score(y_test, lr_test_pred, 'precision')))\n",
    "print('Logistic Regression Recall on test : {}'.format(score(y_test, lr_test_pred, 'recall')))\n",
    "print('Logistic Regression Hit Rate on test : {}'.format(score(y_test, lr_test_pred, 'hit')))\n",
    "print('Logistic Regression F1 Score on test : {}'.format(score(y_test, lr_test_pred, 'f1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_tuning_parameters = {'estimator__C': [0.1, 5, 50, 100, 1000],\n",
    "                         'estimator__kernel': ['rbf']}\n",
    "svm = OneVsRestClassifier(SVC())\n",
    "svm = GridSearchCV(svm, param_grid = svm_tuning_parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=1),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'estimator__C': [0.1, 5, 50, 100, 1000], 'estimator__kernel': ['rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(word2vec_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "filename = 'svm_word2vec.pkl'\n",
    "pickle.dump(svm, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_svm = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_train_pred = loaded_svm.predict(word2vec_X_train)\n",
    "svm_test_pred = loaded_svm.predict(word2vec_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Avg Accuracy on train : 0.8427199770707939\n",
      "SVM Exact Accuracy on train : 0.02722843221553454\n",
      "SVM Precision on train : 0.026769848094009747\n",
      "SVM Recall on train : 0.05\n",
      "SVM Hit Rate on train : 0.4044138721696761\n",
      "SVM F1 Score on train : 0.06329045937446505\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('SVM Avg Accuracy on train : {}'.format(score(y_train, svm_train_pred, 'avg')))\n",
    "print('SVM Exact Accuracy on train : {}'.format(score(y_train, svm_train_pred, 'exact')))\n",
    "print('SVM Precision on train : {}'.format(score(y_train, svm_train_pred, 'precision')))\n",
    "print('SVM Recall on train : {}'.format(score(y_train, svm_train_pred, 'recall')))\n",
    "print('SVM Hit Rate on train : {}'.format(score(y_train,lr_train_pred, 'hit')))\n",
    "print('SVM F1 Score on train : {}'.format(score(y_train, lr_train_pred, 'f1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Avg Accuracy on test : 0.8403780068728522\n",
      "SVM Exact Accuracy on test : 0.026345933562428408\n",
      "SVM Precision on test : 0.026403207331042382\n",
      "SVM Recall on test : 0.05\n",
      "SVM Hit Rate on test : 0.5280641466208477\n",
      "SVM F1 Score on test : 0.034557721139430286\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print('SVM Avg Accuracy on test : {}'.format(score(y_test, svm_test_pred, 'avg')))\n",
    "print('SVM Exact Accuracy on test : {}'.format(score(y_test, svm_test_pred, 'exact')))\n",
    "print('SVM Precision on test : {}'.format(score(y_test, svm_test_pred, 'precision')))\n",
    "print('SVM Recall on test : {}'.format(score(y_test, svm_test_pred, 'recall')))\n",
    "print('SVM Hit Rate on test : {}'.format(score(y_test, svm_test_pred, 'hit')))\n",
    "print('SVM F1 Score on test : {}'.format(score(y_test, svm_test_pred, 'f1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_w2v = Sequential()\n",
    "e = Embedding(w2v_matrix.shape[0], EMBEDDING_DIM, \n",
    "              weights=[w2v_matrix], \n",
    "              input_length=MAX_SEQUENCE_LENGTH, \n",
    "              trainable=False)\n",
    "lstm_w2v.add(e)\n",
    "# lstm_w2v.add(Dropout(0.5))\n",
    "# lstm_w2v.add(Conv1D(40, 2))\n",
    "lstm_w2v.add(LSTM(80, dropout = 0.5, recurrent_dropout=0.5))\n",
    "# lstm_w2v.add(Dense(40, activation='relu'))\n",
    "lstm_w2v.add(Dense(20, activation='sigmoid'))\n",
    "lstm_w2v.compile(optimizer=Adam(lr=0.002), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm_w2v.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
    "lstm_w2v.fit(X_w2v_train, y_train, validation_data= (X_w2v_test, y_test),\n",
    "               batch_size=128,\n",
    "               epochs=120);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lstm_w2v.save('lstm_w2v_55_25_150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_w2v = load_model('lstm_w2v_55_25_150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 200, 300)          13495200  \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 80)                121920    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                1620      \n",
      "=================================================================\n",
      "Total params: 13,618,740\n",
      "Trainable params: 123,540\n",
      "Non-trainable params: 13,495,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_w2v.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Avg Accuracy on test : 0.8624856815578466\n",
      "Word2Vec Exact Accuracy on test : 0.061855670103092786\n",
      "Word2Vec Precision on test : 0.5525787967604396\n",
      "Word2Vec Recall on test : 0.2585768591891645\n",
      "Word2Vec Hit Rate on test : 0.7800687285223368\n",
      "Word2VecF1 on test : 0.3522975859758274\n"
     ]
    }
   ],
   "source": [
    "lstm_pred_w2v_test = lstm_w2v.predict(X_w2v_test)\n",
    "# evaluation\n",
    "print('Word2Vec Avg Accuracy on test : {}'.format(score_thres(y_test, lstm_pred_w2v_test, method='avg')))\n",
    "print('Word2Vec Exact Accuracy on test : {}'.format(score_thres(y_test, lstm_pred_w2v_test, method='exact')))\n",
    "print('Word2Vec Precision on test : {}'.format(score_thres(y_test, lstm_pred_w2v_test, method='precision')))\n",
    "print('Word2Vec Recall on test : {}'.format(score_thres(y_test, lstm_pred_w2v_test, method='recall')))\n",
    "print('Word2Vec Hit Rate on test : {}'.format(score_thres(y_test, lstm_pred_w2v_test, method='hit')))\n",
    "print('Word2VecF1 on test : {}'.format(score_thres(y_test, lstm_pred_w2v_test, method='f1')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
